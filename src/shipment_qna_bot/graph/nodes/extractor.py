import re
from typing import Any, Dict, List

from shipment_qna_bot.graph.state import GraphState
from shipment_qna_bot.logging.logger import logger
from shipment_qna_bot.tools.azure_openai_chat import AzureOpenAIChatTool

_CHAT_TOOL = None


def _get_chat_tool() -> AzureOpenAIChatTool:
    global _CHAT_TOOL
    if _CHAT_TOOL is None:
        _CHAT_TOOL = AzureOpenAIChatTool()
    return _CHAT_TOOL


def extractor_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Extracts entities (Container, PO, OBL, Booking, Dates, Locations) from the normalized question.
    """
    text = state.get("normalized_question") or state.get("question_raw") or ""

    # 1. Regex handles high-confidence ID extraction
    container_pattern = r"\b[a-zA-Z]{4}\d{7}\b"
    po_pattern = r"\b(?:PO)?(\d{10})\b"
    # Booking numbers usually start with 2-3 letters + 7-10 digits, or just 10 digits
    booking_pattern = r"\b(?:[a-zA-Z]{2,3})?\d{7,10}\b"

    containers = [c.upper() for c in re.findall(container_pattern, text)]
    pos = [p for p in re.findall(po_pattern, text, re.IGNORECASE)]

    # 2. LLM handles ambiguous entities (Locations, Dates, Carriers, and validating regex results)
    system_prompt = """
    Extract logistics entities from the user's question. 
    Return a JSON object with keys: 
    - "container": list of container IDs (e.g. SEGU5935510)
    - "po": list of PO numbers (10 digits)
    - "booking": list of booking numbers (e.g. TH2017996)
    - "obl": list of Ocean Bill of Lading numbers
    - "location": list of cities or ports (e.g. "Los Angeles", "CNSHA")
    - "carrier": list of shipping lines (e.g. "Maersk", "MSC")
    - "date_range": e.g. "Oct", "November 25", "December"
    - "status_keywords": e.g. "on water", "delivered", "delayed", "hot"

    If nothing is found for a key, return an empty list.
    """.strip()

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": text},
    ]

    llm_extracted = {}
    usage_metadata = state.get("usage_metadata") or {
        "prompt_tokens": 0,
        "completion_tokens": 0,
        "total_tokens": 0,
    }
    try:
        chat = _get_chat_tool()
        import json

        response = chat.chat_completion(messages, temperature=0.0)
        res = response["content"]
        usage = response["usage"]

        # Accumulate usage
        for k in usage:
            usage_metadata[k] = usage_metadata.get(k, 0) + usage[k]

        # Find JSON block in response
        json_match = re.search(r"\{.*\}", res, re.DOTALL)
        if json_match:
            llm_extracted = json.loads(json_match.group(0))
    except Exception as e:
        logger.warning(f"LLM Extraction failed: {e}. Falling back to regex.")

    # Merge results
    merged = {
        "container": list(set(containers + (llm_extracted.get("container") or []))),
        "po": list(set(pos + (llm_extracted.get("po") or []))),
        "booking": llm_extracted.get("booking") or [],
        "obl": llm_extracted.get("obl") or [],
        "location": llm_extracted.get("location") or [],
        "carrier": llm_extracted.get("carrier") or [],
        "date_range": llm_extracted.get("date_range") or [],
        "status_keywords": llm_extracted.get("status_keywords") or [],
    }

    count = sum(len(v) if isinstance(v, list) else 1 for v in merged.values() if v)
    logger.info(
        f"Extracted {count} entities", extra={"extra_data": {"extracted": merged}}
    )

    return {"extracted_ids": merged, "usage_metadata": usage_metadata}
